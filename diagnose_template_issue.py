#!/usr/bin/env python3
"""
ä¸“é—¨è¯Šæ–­ç”Ÿäº§ç¯å¢ƒæ¨¡æ¿å ä½ç¬¦è¯†åˆ«é—®é¢˜çš„å·¥å…·
åˆ†æä¸ºä»€ä¹ˆç³»ç»Ÿæ˜¾ç¤º0ä¸ªå ä½ç¬¦ä½†å®é™…æœ‰13ä¸ªæ•°æ®å­—æ®µ
"""

import os
import zipfile
import xml.etree.ElementTree as ET
import re
from pathlib import Path
import tempfile

def analyze_template_placeholders(docx_path):
    """æ·±åº¦åˆ†æWordæ¨¡æ¿ä¸­çš„å ä½ç¬¦é—®é¢˜"""
    
    print(f"ğŸ” æ·±åº¦åˆ†ææ¨¡æ¿: {docx_path}")
    
    if not os.path.exists(docx_path):
        print(f"âŒ æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {docx_path}")
        return
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        # è§£å‹docxæ–‡ä»¶
        with zipfile.ZipFile(docx_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)
        
        # è¯»å–document.xml
        document_xml_path = os.path.join(temp_dir, 'word', 'document.xml')
        
        if not os.path.exists(document_xml_path):
            print("âŒ æ— æ³•æ‰¾åˆ°document.xmlæ–‡ä»¶")
            return
        
        with open(document_xml_path, 'r', encoding='utf-8') as f:
            xml_content = f.read()
        
        print(f"ğŸ“„ XMLå†…å®¹é•¿åº¦: {len(xml_content)} å­—ç¬¦")
        
        # 1. åˆ†ææ ‡å‡†åŒèŠ±æ‹¬å·å ä½ç¬¦
        analyze_standard_placeholders(xml_content)
        
        # 2. åˆ†æå¯èƒ½è¢«åˆ†å‰²çš„å ä½ç¬¦
        analyze_fragmented_placeholders(xml_content)
        
        # 3. åˆ†æå•èŠ±æ‹¬å·æ ¼å¼
        analyze_single_bracket_placeholders(xml_content)
        
        # 4. åˆ†æWordç‰¹æ®Šæ ¼å¼
        analyze_word_specific_formats(xml_content)
        
        # 5. æœç´¢å·²çŸ¥çš„13ä¸ªå­—æ®µ
        search_known_fields(xml_content)
        
        # 6. åˆ†æXMLç»“æ„é—®é¢˜
        analyze_xml_structure(xml_content)

def analyze_standard_placeholders(xml_content):
    """åˆ†ææ ‡å‡†{{}}æ ¼å¼çš„å ä½ç¬¦"""
    print("\nğŸ”– æ ‡å‡†åŒèŠ±æ‹¬å·å ä½ç¬¦åˆ†æ:")
    
    pattern = r'\{\{([^}]+)\}\}'
    matches = re.findall(pattern, xml_content)
    
    if matches:
        print(f"âœ… æ‰¾åˆ° {len(matches)} ä¸ªæ ‡å‡†æ ¼å¼å ä½ç¬¦:")
        for i, match in enumerate(matches, 1):
            print(f"  {i:2d}. {{{{ {match} }}}}")
    else:
        print("âŒ æœªæ‰¾åˆ°æ ‡å‡†æ ¼å¼å ä½ç¬¦")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸å®Œæ•´çš„èŠ±æ‹¬å·
        incomplete_patterns = [
            r'\{\{[^}]*$',  # å¼€å§‹ä½†æœªç»“æŸ
            r'^[^{]*\}\}',  # ç»“æŸä½†æœªå¼€å§‹
            r'\{[^{][^}]*\}',  # å•èŠ±æ‹¬å·
        ]
        
        for pattern_name, pattern in [
            ("æœªç»“æŸçš„å ä½ç¬¦", r'\{\{[^}]*$'),
            ("æœªå¼€å§‹çš„å ä½ç¬¦", r'^[^{]*\}\}'),
            ("å•èŠ±æ‹¬å·æ ¼å¼", r'\{[^{][^}]*\}')
        ]:
            matches = re.findall(pattern, xml_content, re.MULTILINE)
            if matches:
                print(f"âš ï¸  å‘ç° {pattern_name}: {len(matches)} ä¸ª")
                for match in matches[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    {match}")

def analyze_fragmented_placeholders(xml_content):
    """åˆ†æè¢«XMLèŠ‚ç‚¹åˆ†å‰²çš„å ä½ç¬¦"""
    print("\nğŸ§© åˆ†å‰²å ä½ç¬¦åˆ†æ:")
    
    # Wordç»å¸¸ä¼šå°†å ä½ç¬¦åˆ†å‰²ï¼Œå¦‚: <w:t>{{ç”²æ–¹</w:t><w:t>å…¬å¸åç§°}}</w:t>
    # æŸ¥æ‰¾å¯èƒ½çš„åˆ†å‰²æ¨¡å¼
    fragmented_patterns = [
        r'<w:t[^>]*>\{\{[^<]*</w:t>.*?<w:t[^>]*>[^}]*\}\}</w:t>',
        r'\{\{[^}]*<[^>]+>[^}]*\}\}',
        r'<w:t[^>]*>[^<]*ç”²æ–¹[^<]*</w:t>',
        r'<w:t[^>]*>[^<]*ä¹™æ–¹[^<]*</w:t>',
        r'<w:t[^>]*>[^<]*åˆåŒ[^<]*</w:t>',
        r'<w:t[^>]*>[^<]*å…¬å¸[^<]*</w:t>',
        r'<w:t[^>]*>[^<]*åç§°[^<]*</w:t>',
    ]
    
    found_fragments = []
    for pattern in fragmented_patterns:
        matches = re.findall(pattern, xml_content, re.IGNORECASE)
        found_fragments.extend(matches)
    
    if found_fragments:
        print(f"âš ï¸  å‘ç° {len(found_fragments)} ä¸ªå¯èƒ½çš„åˆ†å‰²ç‰‡æ®µ:")
        for i, fragment in enumerate(found_fragments[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  {i:2d}. {fragment[:100]}...")
    else:
        print("âŒ æœªæ‰¾åˆ°æ˜æ˜¾çš„åˆ†å‰²ç‰‡æ®µ")

def analyze_single_bracket_placeholders(xml_content):
    """åˆ†æå•èŠ±æ‹¬å·æ ¼å¼çš„å ä½ç¬¦"""
    print("\nğŸ”— å•èŠ±æ‹¬å·å ä½ç¬¦åˆ†æ:")
    
    pattern = r'\{([^{}]+)\}'
    matches = re.findall(pattern, xml_content)
    
    # è¿‡æ»¤æ‰XMLæ ‡ç­¾å’Œå…¶ä»–éå ä½ç¬¦å†…å®¹
    valid_matches = []
    for match in matches:
        if (not '<' in match and not '>' in match and 
            not 'w:' in match and len(match.strip()) > 0 and
            len(match) < 50):  # åˆç†çš„é•¿åº¦é™åˆ¶
            valid_matches.append(match.strip())
    
    if valid_matches:
        print(f"âœ… æ‰¾åˆ° {len(valid_matches)} ä¸ªå•èŠ±æ‹¬å·æ ¼å¼å ä½ç¬¦:")
        for i, match in enumerate(valid_matches, 1):
            print(f"  {i:2d}. {{ {match} }}")
    else:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å•èŠ±æ‹¬å·å ä½ç¬¦")

def analyze_word_specific_formats(xml_content):
    """åˆ†æWordç‰¹æ®Šæ ¼å¼"""
    print("\nğŸ“ Wordç‰¹æ®Šæ ¼å¼åˆ†æ:")
    
    # æ£€æŸ¥WordåŸŸä»£ç 
    field_patterns = [
        r'<w:fldChar[^>]*w:fldCharType="begin"[^>]*/>.*?<w:fldChar[^>]*w:fldCharType="end"[^>]*/>',
        r'MERGEFIELD\s+([^\s]+)',
        r'<w:instrText[^>]*>([^<]+)</w:instrText>',
    ]
    
    for pattern_name, pattern in [
        ("WordåŸŸä»£ç ", r'<w:fldChar[^>]*w:fldCharType="begin"[^>]*/>.*?<w:fldChar[^>]*w:fldCharType="end"[^>]*/>'),
        ("MERGEFIELD", r'MERGEFIELD\s+([^\s]+)'),
        ("æŒ‡ä»¤æ–‡æœ¬", r'<w:instrText[^>]*>([^<]+)</w:instrText>')
    ]:
        matches = re.findall(pattern, xml_content, re.IGNORECASE | re.DOTALL)
        if matches:
            print(f"âœ… æ‰¾åˆ° {pattern_name}: {len(matches)} ä¸ª")
            for i, match in enumerate(matches[:5], 1):
                print(f"  {i:2d}. {match[:100]}...")
        else:
            print(f"âŒ æœªæ‰¾åˆ° {pattern_name}")

def search_known_fields(xml_content):
    """æœç´¢å·²çŸ¥çš„13ä¸ªå­—æ®µ"""
    print("\nğŸ¯ æœç´¢å·²çŸ¥å­—æ®µ:")
    
    known_fields = [
        "ç”²æ–¹å…¬å¸åç§°", "ä¹™æ–¹å…¬å¸åç§°", "åˆåŒç±»å‹", "åˆåŒé‡‘é¢", "ç­¾ç½²æ—¥æœŸ",
        "ç”²æ–¹è”ç³»äºº", "ç”²æ–¹ç”µè¯", "ä¹™æ–¹è”ç³»äºº", "è”ç³»é‚®ç®±", "ä»˜æ¬¾æ–¹å¼",
        "äº§å“æ¸…å•", "æ˜¯å¦åŒ…å«ä¿é™©", "ç‰¹åˆ«çº¦å®š"
    ]
    
    found_fields = []
    for field in known_fields:
        # æœç´¢å„ç§å¯èƒ½çš„æ ¼å¼
        patterns = [
            f"\\{{\\{{{field}\\}}\\}}",  # {{å­—æ®µå}}
            f"\\{{{field}\\}}",         # {å­—æ®µå}
            f"{field}",                 # ç›´æ¥æ–‡æœ¬
        ]
        
        field_found = False
        for pattern in patterns:
            if re.search(pattern, xml_content):
                found_fields.append((field, pattern))
                field_found = True
                break
        
        if not field_found:
            # æ¨¡ç³Šæœç´¢
            for word in field.split():
                if word in xml_content:
                    print(f"  ğŸ” åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°å…³é”®è¯: {word}")
    
    if found_fields:
        print(f"âœ… æ‰¾åˆ° {len(found_fields)} ä¸ªå·²çŸ¥å­—æ®µ:")
        for field, pattern in found_fields:
            print(f"  âœ“ {field} (æ ¼å¼: {pattern})")
    else:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å·²çŸ¥å­—æ®µçš„æ ‡å‡†æ ¼å¼")

def analyze_xml_structure(xml_content):
    """åˆ†æXMLç»“æ„é—®é¢˜"""
    print("\nğŸ—ï¸  XMLç»“æ„åˆ†æ:")
    
    # ç»Ÿè®¡å…³é”®XMLå…ƒç´ 
    elements = {
        'w:t': len(re.findall(r'<w:t[^>]*>', xml_content)),
        'w:r': len(re.findall(r'<w:r[^>]*>', xml_content)),
        'w:p': len(re.findall(r'<w:p[^>]*>', xml_content)),
        'w:tbl': len(re.findall(r'<w:tbl[^>]*>', xml_content)),
    }
    
    print("ğŸ“Š XMLå…ƒç´ ç»Ÿè®¡:")
    for element, count in elements.items():
        print(f"  {element}: {count} ä¸ª")
    
    # æ£€æŸ¥æ–‡æœ¬å†…å®¹
    text_elements = re.findall(r'<w:t[^>]*>([^<]+)</w:t>', xml_content)
    print(f"\nğŸ“ æ–‡æœ¬å…ƒç´ : {len(text_elements)} ä¸ª")
    
    # æŸ¥æ‰¾åŒ…å«ä¸­æ–‡çš„æ–‡æœ¬å…ƒç´ 
    chinese_texts = [text for text in text_elements if re.search(r'[\u4e00-\u9fa5]', text)]
    print(f"ğŸ‡¨ğŸ‡³ åŒ…å«ä¸­æ–‡çš„æ–‡æœ¬: {len(chinese_texts)} ä¸ª")
    
    if chinese_texts:
        print("å‰10ä¸ªä¸­æ–‡æ–‡æœ¬ç¤ºä¾‹:")
        for i, text in enumerate(chinese_texts[:10], 1):
            print(f"  {i:2d}. {text[:50]}...")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ” ç”Ÿäº§ç¯å¢ƒæ¨¡æ¿å ä½ç¬¦è¯Šæ–­å·¥å…·")
    print("=" * 60)
    
    # æŸ¥æ‰¾æ¨¡æ¿æ–‡ä»¶
    template_name = "é‡‘æ¸¯-å…¨æ—¶é€šã€é‡‘æ¸¯æ¨¡æ¿ã€‘ï¼ˆå¤–è´¸ï¼‰.docx"
    
    # å¯èƒ½çš„è·¯å¾„
    possible_paths = [
        template_name,
        f"./{template_name}",
        f"templates/{template_name}",
        f"../templates/{template_name}",
    ]
    
    template_path = None
    for path in possible_paths:
        if os.path.exists(path):
            template_path = path
            break
    
    if not template_path:
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶: {template_name}")
        print("è¯·å°†æ¨¡æ¿æ–‡ä»¶æ”¾åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€:")
        for path in possible_paths:
            print(f"  - {path}")
        return
    
    print(f"ğŸ“ æ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶: {template_path}")
    
    # åˆ†ææ¨¡æ¿
    analyze_template_placeholders(template_path)
    
    print("\n" + "=" * 60)
    print("âœ… è¯Šæ–­å®Œæˆ")
    
    print("\nğŸ’¡ ä¿®å¤å»ºè®®:")
    print("1. æ£€æŸ¥æ¨¡æ¿ä¸­å ä½ç¬¦çš„å®é™…æ ¼å¼")
    print("2. ç¡®è®¤æ˜¯å¦ä½¿ç”¨äº†WordåŸŸä»£ç æˆ–å…¶ä»–ç‰¹æ®Šæ ¼å¼")
    print("3. éªŒè¯å ä½ç¬¦æ˜¯å¦è¢«XMLèŠ‚ç‚¹åˆ†å‰²")
    print("4. è€ƒè™‘ä½¿ç”¨æ›´å¼ºå¤§çš„å ä½ç¬¦è¯†åˆ«ç®—æ³•")

if __name__ == '__main__':
    main()
