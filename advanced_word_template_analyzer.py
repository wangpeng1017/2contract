#!/usr/bin/env python3
"""
é«˜çº§Wordæ¨¡æ¿åˆ†æå·¥å…· - ä¸“é—¨åˆ†æä¸“ä¸šWordæ¨¡æ¿çš„å¤æ‚ç»“æ„
æ£€æµ‹å†…å®¹æ§ä»¶ã€ä¹¦ç­¾ã€è¡¨æ ¼ã€è¡¨å•å­—æ®µç­‰é«˜çº§åŠŸèƒ½
"""

import os
import zipfile
import xml.etree.ElementTree as ET
import re
from pathlib import Path
import tempfile
import json

class AdvancedWordTemplateAnalyzer:
    def __init__(self, docx_path):
        self.docx_path = docx_path
        self.temp_dir = None
        self.document_xml = None
        self.content_types = None
        self.relationships = None
        
    def analyze(self):
        """æ‰§è¡Œå®Œæ•´çš„Wordæ¨¡æ¿åˆ†æ"""
        print(f"ğŸ” é«˜çº§Wordæ¨¡æ¿åˆ†æ: {self.docx_path}")
        print("=" * 80)
        
        if not os.path.exists(self.docx_path):
            print(f"âŒ æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {self.docx_path}")
            return
        
        # è§£å‹å¹¶è¯»å–æ–‡ä»¶
        with tempfile.TemporaryDirectory() as temp_dir:
            self.temp_dir = temp_dir
            self._extract_docx()
            self._load_xml_files()
            
            # æ‰§è¡Œå„ç§åˆ†æ
            self._analyze_document_structure()
            self._analyze_content_controls()
            self._analyze_bookmarks()
            self._analyze_form_fields()
            self._analyze_tables()
            self._analyze_text_patterns()
            self._analyze_custom_xml()
            self._generate_recommendations()
    
    def _extract_docx(self):
        """è§£å‹docxæ–‡ä»¶"""
        with zipfile.ZipFile(self.docx_path, 'r') as zip_ref:
            zip_ref.extractall(self.temp_dir)
    
    def _load_xml_files(self):
        """åŠ è½½å…³é”®XMLæ–‡ä»¶"""
        # ä¸»æ–‡æ¡£
        document_path = os.path.join(self.temp_dir, 'word', 'document.xml')
        if os.path.exists(document_path):
            with open(document_path, 'r', encoding='utf-8') as f:
                self.document_xml = f.read()
        
        # å†…å®¹ç±»å‹
        content_types_path = os.path.join(self.temp_dir, '[Content_Types].xml')
        if os.path.exists(content_types_path):
            with open(content_types_path, 'r', encoding='utf-8') as f:
                self.content_types = f.read()
        
        # å…³ç³»æ–‡ä»¶
        rels_path = os.path.join(self.temp_dir, 'word', '_rels', 'document.xml.rels')
        if os.path.exists(rels_path):
            with open(rels_path, 'r', encoding='utf-8') as f:
                self.relationships = f.read()
    
    def _analyze_document_structure(self):
        """åˆ†ææ–‡æ¡£åŸºæœ¬ç»“æ„"""
        print("\nğŸ“„ æ–‡æ¡£ç»“æ„åˆ†æ:")
        
        if not self.document_xml:
            print("âŒ æ— æ³•è¯»å–document.xml")
            return
        
        # ç»Ÿè®¡åŸºæœ¬å…ƒç´ 
        elements = {
            'æ®µè½ (w:p)': len(re.findall(r'<w:p[^>]*>', self.document_xml)),
            'æ–‡æœ¬è¿è¡Œ (w:r)': len(re.findall(r'<w:r[^>]*>', self.document_xml)),
            'æ–‡æœ¬ (w:t)': len(re.findall(r'<w:t[^>]*>', self.document_xml)),
            'è¡¨æ ¼ (w:tbl)': len(re.findall(r'<w:tbl[^>]*>', self.document_xml)),
            'è¡¨æ ¼è¡Œ (w:tr)': len(re.findall(r'<w:tr[^>]*>', self.document_xml)),
            'è¡¨æ ¼å•å…ƒæ ¼ (w:tc)': len(re.findall(r'<w:tc[^>]*>', self.document_xml)),
        }
        
        for element, count in elements.items():
            print(f"  {element}: {count} ä¸ª")
        
        print(f"  XMLæ€»é•¿åº¦: {len(self.document_xml):,} å­—ç¬¦")
    
    def _analyze_content_controls(self):
        """åˆ†æWordå†…å®¹æ§ä»¶"""
        print("\nğŸ›ï¸  å†…å®¹æ§ä»¶åˆ†æ:")
        
        if not self.document_xml:
            return
        
        # æŸ¥æ‰¾æ‰€æœ‰å†…å®¹æ§ä»¶
        sdt_pattern = r'<w:sdt[^>]*>.*?</w:sdt>'
        sdt_matches = re.findall(sdt_pattern, self.document_xml, re.DOTALL)
        
        print(f"  æ‰¾åˆ° {len(sdt_matches)} ä¸ªå†…å®¹æ§ä»¶")
        
        for i, sdt in enumerate(sdt_matches, 1):
            print(f"\n  å†…å®¹æ§ä»¶ {i}:")
            
            # æå–æ ‡é¢˜
            title_match = re.search(r'<w:tag w:val="([^"]*)"', sdt)
            if title_match:
                print(f"    æ ‡ç­¾: {title_match.group(1)}")
            
            # æå–åˆ«å
            alias_match = re.search(r'<w:alias w:val="([^"]*)"', sdt)
            if alias_match:
                print(f"    åˆ«å: {alias_match.group(1)}")
            
            # æå–å ä½ç¬¦æ–‡æœ¬
            placeholder_match = re.search(r'<w:placeholder>.*?<w:docPart w:val="([^"]*)"', sdt, re.DOTALL)
            if placeholder_match:
                print(f"    å ä½ç¬¦: {placeholder_match.group(1)}")
            
            # æå–æ–‡æœ¬å†…å®¹
            text_matches = re.findall(r'<w:t[^>]*>([^<]*)</w:t>', sdt)
            if text_matches:
                content = ''.join(text_matches)
                print(f"    å†…å®¹: {content[:100]}...")
    
    def _analyze_bookmarks(self):
        """åˆ†æä¹¦ç­¾"""
        print("\nğŸ”– ä¹¦ç­¾åˆ†æ:")
        
        if not self.document_xml:
            return
        
        # æŸ¥æ‰¾ä¹¦ç­¾å¼€å§‹æ ‡è®°
        bookmark_starts = re.findall(r'<w:bookmarkStart[^>]*w:name="([^"]*)"[^>]*>', self.document_xml)
        
        print(f"  æ‰¾åˆ° {len(bookmark_starts)} ä¸ªä¹¦ç­¾:")
        for i, bookmark in enumerate(bookmark_starts, 1):
            print(f"    {i:2d}. {bookmark}")
            
            # æŸ¥æ‰¾ä¹¦ç­¾å†…å®¹
            bookmark_pattern = f'<w:bookmarkStart[^>]*w:name="{re.escape(bookmark)}"[^>]*>.*?<w:bookmarkEnd[^>]*>'
            bookmark_content = re.search(bookmark_pattern, self.document_xml, re.DOTALL)
            if bookmark_content:
                text_matches = re.findall(r'<w:t[^>]*>([^<]*)</w:t>', bookmark_content.group(0))
                if text_matches:
                    content = ''.join(text_matches)
                    print(f"        å†…å®¹: {content[:50]}...")
    
    def _analyze_form_fields(self):
        """åˆ†æè¡¨å•å­—æ®µ"""
        print("\nğŸ“ è¡¨å•å­—æ®µåˆ†æ:")
        
        if not self.document_xml:
            return
        
        # æŸ¥æ‰¾è¡¨å•å­—æ®µ
        form_fields = re.findall(r'<w:fldChar[^>]*w:fldCharType="begin"[^>]*>.*?<w:fldChar[^>]*w:fldCharType="end"[^>]*>', self.document_xml, re.DOTALL)
        
        print(f"  æ‰¾åˆ° {len(form_fields)} ä¸ªè¡¨å•å­—æ®µ")
        
        # æŸ¥æ‰¾FORMTEXTå­—æ®µ
        formtext_pattern = r'FORMTEXT'
        formtext_matches = re.findall(formtext_pattern, self.document_xml)
        print(f"  FORMTEXTå­—æ®µ: {len(formtext_matches)} ä¸ª")
        
        # æŸ¥æ‰¾MERGEFIELDå­—æ®µ
        mergefield_pattern = r'MERGEFIELD\s+([^\s\\]+)'
        mergefield_matches = re.findall(mergefield_pattern, self.document_xml)
        print(f"  MERGEFIELDå­—æ®µ: {len(mergefield_matches)} ä¸ª")
        for field in mergefield_matches:
            print(f"    - {field}")
    
    def _analyze_tables(self):
        """åˆ†æè¡¨æ ¼ä¸­çš„å ä½ç¬¦"""
        print("\nğŸ“Š è¡¨æ ¼åˆ†æ:")
        
        if not self.document_xml:
            return
        
        # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼
        table_pattern = r'<w:tbl[^>]*>.*?</w:tbl>'
        tables = re.findall(table_pattern, self.document_xml, re.DOTALL)
        
        print(f"  æ‰¾åˆ° {len(tables)} ä¸ªè¡¨æ ¼")
        
        for i, table in enumerate(tables, 1):
            print(f"\n  è¡¨æ ¼ {i}:")
            
            # ç»Ÿè®¡è¡Œå’Œåˆ—
            rows = re.findall(r'<w:tr[^>]*>', table)
            cells = re.findall(r'<w:tc[^>]*>', table)
            print(f"    è¡Œæ•°: {len(rows)}, å•å…ƒæ ¼æ•°: {len(cells)}")
            
            # æŸ¥æ‰¾è¡¨æ ¼ä¸­çš„å ä½ç¬¦
            placeholders = []
            
            # åŒèŠ±æ‹¬å·
            double_brackets = re.findall(r'\{\{([^}]+)\}\}', table)
            placeholders.extend(double_brackets)
            
            # å•èŠ±æ‹¬å·
            single_brackets = re.findall(r'\{([^{}]+)\}', table)
            placeholders.extend([p for p in single_brackets if not any(c in p for c in '<>')])
            
            # æŸ¥æ‰¾åŒ…å«å·²çŸ¥å­—æ®µåçš„å•å…ƒæ ¼
            known_fields = [
                "ç”²æ–¹å…¬å¸åç§°", "ä¹™æ–¹å…¬å¸åç§°", "åˆåŒç±»å‹", "åˆåŒé‡‘é¢", "ç­¾ç½²æ—¥æœŸ",
                "ç”²æ–¹è”ç³»äºº", "ç”²æ–¹ç”µè¯", "ä¹™æ–¹è”ç³»äºº", "è”ç³»é‚®ç®±", "ä»˜æ¬¾æ–¹å¼",
                "äº§å“æ¸…å•", "æ˜¯å¦åŒ…å«ä¿é™©", "ç‰¹åˆ«çº¦å®š"
            ]
            
            for field in known_fields:
                if field in table:
                    print(f"    åŒ…å«å­—æ®µ: {field}")
            
            if placeholders:
                print(f"    å ä½ç¬¦: {list(set(placeholders))}")
    
    def _analyze_text_patterns(self):
        """åˆ†ææ–‡æœ¬æ¨¡å¼"""
        print("\nğŸ”¤ æ–‡æœ¬æ¨¡å¼åˆ†æ:")
        
        if not self.document_xml:
            return
        
        # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
        text_elements = re.findall(r'<w:t[^>]*>([^<]+)</w:t>', self.document_xml)
        all_text = ' '.join(text_elements)
        
        print(f"  æ€»æ–‡æœ¬é•¿åº¦: {len(all_text)} å­—ç¬¦")
        
        # æŸ¥æ‰¾å„ç§å¯èƒ½çš„å ä½ç¬¦æ¨¡å¼
        patterns = {
            'åŒèŠ±æ‹¬å· {{}}': r'\{\{([^}]+)\}\}',
            'å•èŠ±æ‹¬å· {}': r'\{([^{}]+)\}',
            'æ–¹æ‹¬å· []': r'\[([^\]]+)\]',
            'ä¸‹åˆ’çº¿ ___': r'_{3,}',
            'ç‚¹çº¿ ...': r'\.{3,}',
            'ç©ºæ ¼å ä½': r'\s{5,}',
        }
        
        for pattern_name, pattern in patterns.items():
            matches = re.findall(pattern, all_text)
            if matches:
                print(f"  {pattern_name}: {len(matches)} ä¸ª")
                for match in matches[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"    - {match}")
        
        # æŸ¥æ‰¾å·²çŸ¥å­—æ®µå
        known_fields = [
            "ç”²æ–¹å…¬å¸åç§°", "ä¹™æ–¹å…¬å¸åç§°", "åˆåŒç±»å‹", "åˆåŒé‡‘é¢", "ç­¾ç½²æ—¥æœŸ",
            "ç”²æ–¹è”ç³»äºº", "ç”²æ–¹ç”µè¯", "ä¹™æ–¹è”ç³»äºº", "è”ç³»é‚®ç®±", "ä»˜æ¬¾æ–¹å¼",
            "äº§å“æ¸…å•", "æ˜¯å¦åŒ…å«ä¿é™©", "ç‰¹åˆ«çº¦å®š"
        ]
        
        found_fields = []
        for field in known_fields:
            if field in all_text:
                found_fields.append(field)
        
        print(f"\n  æ‰¾åˆ°çš„å·²çŸ¥å­—æ®µ ({len(found_fields)}/13):")
        for field in found_fields:
            print(f"    âœ“ {field}")
        
        missing_fields = [f for f in known_fields if f not in found_fields]
        if missing_fields:
            print(f"\n  æœªæ‰¾åˆ°çš„å­—æ®µ ({len(missing_fields)}/13):")
            for field in missing_fields:
                print(f"    âœ— {field}")
    
    def _analyze_custom_xml(self):
        """åˆ†æè‡ªå®šä¹‰XMLéƒ¨åˆ†"""
        print("\nğŸ”§ è‡ªå®šä¹‰XMLåˆ†æ:")
        
        # æ£€æŸ¥customXmlæ–‡ä»¶å¤¹
        custom_xml_dir = os.path.join(self.temp_dir, 'customXml')
        if os.path.exists(custom_xml_dir):
            xml_files = [f for f in os.listdir(custom_xml_dir) if f.endswith('.xml')]
            print(f"  æ‰¾åˆ° {len(xml_files)} ä¸ªè‡ªå®šä¹‰XMLæ–‡ä»¶:")
            for xml_file in xml_files:
                print(f"    - {xml_file}")
        else:
            print("  æœªæ‰¾åˆ°è‡ªå®šä¹‰XMLæ–‡ä»¶")
    
    def _generate_recommendations(self):
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        print("\nğŸ’¡ ä¿®å¤å»ºè®®:")
        print("=" * 50)
        
        print("1. **å¢å¼ºå†…å®¹æ§ä»¶æ”¯æŒ**:")
        print("   - åœ¨WordProcessorä¸­æ·»åŠ <w:sdt>æ ‡ç­¾è¯†åˆ«")
        print("   - æ”¯æŒé€šè¿‡w:tagå’Œw:aliaså±æ€§åŒ¹é…å­—æ®µ")
        print("   - å®ç°å†…å®¹æ§ä»¶å†…å®¹æ›¿æ¢")
        
        print("\n2. **å¢å¼ºä¹¦ç­¾æ”¯æŒ**:")
        print("   - è¯†åˆ«<w:bookmarkStart>å’Œ<w:bookmarkEnd>")
        print("   - æ”¯æŒä¹¦ç­¾åç§°ä¸å­—æ®µååŒ¹é…")
        print("   - å®ç°ä¹¦ç­¾å†…å®¹æ›¿æ¢")
        
        print("\n3. **å¢å¼ºè¡¨æ ¼å¤„ç†**:")
        print("   - æ·±åº¦æ‰«æè¡¨æ ¼å•å…ƒæ ¼å†…å®¹")
        print("   - æ”¯æŒè¡¨æ ¼ä¸­çš„å„ç§å ä½ç¬¦æ ¼å¼")
        print("   - å¤„ç†è·¨å•å…ƒæ ¼çš„å¤æ‚ç»“æ„")
        
        print("\n4. **å¢å¼ºæ–‡æœ¬æ¨¡å¼è¯†åˆ«**:")
        print("   - æ”¯æŒæ›´å¤šå ä½ç¬¦æ ¼å¼ï¼ˆæ–¹æ‹¬å·ã€ä¸‹åˆ’çº¿ç­‰ï¼‰")
        print("   - æ”¹è¿›è·¨æ–‡æœ¬è¿è¡Œçš„å ä½ç¬¦é‡ç»„")
        print("   - å¢å¼ºä¸­æ–‡å­—æ®µåè¯†åˆ«")
        
        print("\n5. **æµ‹è¯•éªŒè¯**:")
        print("   - åˆ›å»ºä¸“é—¨çš„æµ‹è¯•ç”¨ä¾‹")
        print("   - éªŒè¯æ‰€æœ‰13ä¸ªå­—æ®µçš„è¯†åˆ«å’Œæ›¿æ¢")
        print("   - ç¡®ä¿æ–‡æ¡£ç»“æ„å®Œæ•´æ€§")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” é«˜çº§Wordæ¨¡æ¿åˆ†æå·¥å…·")
    print("ä¸“é—¨åˆ†æä¸“ä¸šWordæ¨¡æ¿çš„å¤æ‚ç»“æ„")
    print("=" * 80)
    
    # æŸ¥æ‰¾æ¨¡æ¿æ–‡ä»¶
    template_name = "é‡‘æ¸¯-å…¨æ—¶é€šã€é‡‘æ¸¯æ¨¡æ¿ã€‘ï¼ˆå¤–è´¸ï¼‰.docx"
    
    # å¯èƒ½çš„è·¯å¾„
    possible_paths = [
        template_name,
        f"./{template_name}",
        f"templates/{template_name}",
        f"../templates/{template_name}",
    ]
    
    template_path = None
    for path in possible_paths:
        if os.path.exists(path):
            template_path = path
            break
    
    if not template_path:
        print(f"âŒ æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶: {template_name}")
        print("è¯·å°†æ¨¡æ¿æ–‡ä»¶æ”¾åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€:")
        for path in possible_paths:
            print(f"  - {path}")
        return
    
    # æ‰§è¡Œåˆ†æ
    analyzer = AdvancedWordTemplateAnalyzer(template_path)
    analyzer.analyze()
    
    print("\n" + "=" * 80)
    print("âœ… é«˜çº§åˆ†æå®Œæˆ")

if __name__ == '__main__':
    main()
