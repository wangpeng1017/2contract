#!/usr/bin/env python3
"""
åˆ†æç”Ÿäº§ç¯å¢ƒç”Ÿæˆçš„æ–‡æ¡£ï¼ŒéªŒè¯å­—æ®µæ›¿æ¢æ˜¯å¦æ­£ç¡®
"""

import os
import zipfile
import xml.etree.ElementTree as ET
from pathlib import Path
import tempfile

def analyze_word_document(docx_path):
    """åˆ†æWordæ–‡æ¡£å†…å®¹ï¼Œæ£€æŸ¥å ä½ç¬¦æ›¿æ¢æƒ…å†µ"""
    
    print(f"ğŸ” åˆ†ææ–‡æ¡£: {docx_path}")
    
    if not os.path.exists(docx_path):
        print(f"âŒ æ–‡æ¡£ä¸å­˜åœ¨: {docx_path}")
        return
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        # è§£å‹docxæ–‡ä»¶
        with zipfile.ZipFile(docx_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)
        
        # è¯»å–document.xml
        document_xml_path = os.path.join(temp_dir, 'word', 'document.xml')
        
        if not os.path.exists(document_xml_path):
            print("âŒ æ— æ³•æ‰¾åˆ°document.xmlæ–‡ä»¶")
            return
        
        with open(document_xml_path, 'r', encoding='utf-8') as f:
            xml_content = f.read()
        
        print(f"ğŸ“„ XMLå†…å®¹é•¿åº¦: {len(xml_content)} å­—ç¬¦")
        
        # åˆ†æå ä½ç¬¦æ›¿æ¢æƒ…å†µ
        analyze_placeholders(xml_content)
        
        # æå–å¯è¯»å†…å®¹
        extract_readable_content(xml_content)

def analyze_placeholders(xml_content):
    """åˆ†æå ä½ç¬¦æ›¿æ¢æƒ…å†µ"""
    
    print("\nğŸ”– å ä½ç¬¦åˆ†æ:")
    
    # æŸ¥æ‰¾å‰©ä½™çš„å ä½ç¬¦
    import re
    remaining_placeholders = re.findall(r'\{\{([^}]+)\}\}', xml_content)
    
    if remaining_placeholders:
        print(f"âŒ å‘ç° {len(remaining_placeholders)} ä¸ªæœªæ›¿æ¢çš„å ä½ç¬¦:")
        for i, placeholder in enumerate(remaining_placeholders, 1):
            print(f"  {i:2d}. {{{{ {placeholder} }}}}")
    else:
        print("âœ… æ²¡æœ‰å‘ç°æœªæ›¿æ¢çš„å ä½ç¬¦")
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æˆ‘ä»¬å¡«å†™çš„æµ‹è¯•æ•°æ®
    test_data = {
        "åŒ—äº¬ç§‘æŠ€æœ‰é™å…¬å¸": "ç”²æ–¹å…¬å¸åç§°",
        "ä¸Šæµ·è´¸æ˜“æœ‰é™å…¬å¸": "ä¹™æ–¹å…¬å¸åç§°", 
        "HT-2024-PROD-001": "åˆåŒç¼–å·",
        "150000": "åˆåŒé‡‘é¢",
        "æœåŠ¡åˆåŒ": "åˆåŒç±»å‹",
        "è½¯ä»¶å¼€å‘ä¸æŠ€æœ¯å’¨è¯¢æœåŠ¡": "æœåŠ¡å†…å®¹",
        "åˆ†æœŸä»˜æ¬¾ï¼Œé¦–ä»˜50%": "ä»˜æ¬¾æ–¹å¼",
        "å¼ ç»ç†": "ç”²æ–¹è”ç³»äºº",
        "138-1234-5678": "ç”²æ–¹ç”µè¯",
        "zhang@beijing-tech.com": "ç”²æ–¹é‚®ç®±",
        "ææ€»ç›‘": "ä¹™æ–¹è”ç³»äºº",
        "139-8765-4321": "ä¹™æ–¹ç”µè¯",
        "2024-01-15": "ç­¾ç½²æ—¥æœŸ",
        "2024-03-15": "äº¤ä»˜æ—¶é—´",
        "æœ¬åˆåŒä¸ºæŠ€æœ¯æœåŠ¡åˆåŒï¼Œéœ€è¦åŒæ–¹ä¸¥æ ¼æŒ‰ç…§çº¦å®šæ‰§è¡Œ": "ç‰¹æ®Šè¯´æ˜",
        "å¦‚æœ‰äº‰è®®ï¼ŒåŒæ–¹åå•†è§£å†³ï¼Œåå•†ä¸æˆå¯å‘åˆåŒç­¾ç½²åœ°æ³•é™¢èµ·è¯‰": "å…¶ä»–æ¡æ¬¾"
    }
    
    print(f"\nğŸ“ æµ‹è¯•æ•°æ®æ›¿æ¢éªŒè¯:")
    replaced_count = 0
    total_count = len(test_data)
    
    for data_value, field_name in test_data.items():
        if data_value in xml_content:
            print(f"  âœ… {field_name}: {data_value}")
            replaced_count += 1
        else:
            print(f"  âŒ {field_name}: {data_value} (æœªæ‰¾åˆ°)")
    
    replacement_rate = (replaced_count / total_count) * 100
    print(f"\nğŸ“Š æ›¿æ¢ç»Ÿè®¡:")
    print(f"  æ€»å­—æ®µæ•°: {total_count}")
    print(f"  æˆåŠŸæ›¿æ¢: {replaced_count}")
    print(f"  æ›¿æ¢æˆåŠŸç‡: {replacement_rate:.1f}%")
    
    if replacement_rate >= 100:
        print("ğŸ‰ æ‰€æœ‰å­—æ®µæ›¿æ¢æˆåŠŸï¼")
    elif replacement_rate >= 80:
        print("âš ï¸  å¤§éƒ¨åˆ†å­—æ®µæ›¿æ¢æˆåŠŸï¼Œä½†ä»æœ‰å°‘é‡é—®é¢˜")
    else:
        print("âŒ å­—æ®µæ›¿æ¢å­˜åœ¨ä¸¥é‡é—®é¢˜")
    
    return replacement_rate

def extract_readable_content(xml_content):
    """æå–å¯è¯»å†…å®¹é¢„è§ˆ"""
    
    print(f"\nğŸ“– æ–‡æ¡£å†…å®¹é¢„è§ˆ:")
    
    try:
        # ç§»é™¤XMLæ ‡ç­¾ï¼Œæå–çº¯æ–‡æœ¬
        import re
        content = re.sub(r'<[^>]*>', ' ', xml_content)
        content = re.sub(r'\s+', ' ', content).strip()
        
        # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        content = content.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
        
        # æ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦
        preview = content[:500]
        if len(content) > 500:
            preview += "..."
        
        print(f"  {preview}")
        
    except Exception as e:
        print(f"  âŒ å†…å®¹æå–å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ” ç”Ÿäº§ç¯å¢ƒæ–‡æ¡£åˆ†æå·¥å…·")
    print("=" * 50)
    
    # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡æ¡£
    base_temp_dir = Path("C:/Users").glob("*/AppData/Local/Temp/playwright-mcp-output")

    docx_files = []
    for temp_dir in base_temp_dir:
        if temp_dir.exists():
            docx_files.extend(temp_dir.glob("*/generated*test-contract-template.docx"))

    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
    if not docx_files:
        alt_paths = [
            Path(tempfile.gettempdir()) / "playwright-mcp-output",
            Path.home() / "Downloads"
        ]
        for alt_path in alt_paths:
            if alt_path.exists():
                docx_files.extend(alt_path.glob("**/generated*test-contract-template.docx"))
    
    if not docx_files:
        print(f"âŒ åœ¨ {download_dir} ä¸­æœªæ‰¾åˆ°ç”Ÿæˆçš„æ–‡æ¡£")
        return
    
    # åˆ†ææœ€æ–°çš„æ–‡æ¡£
    latest_docx = max(docx_files, key=lambda x: x.stat().st_mtime)
    
    print(f"ğŸ“ æ‰¾åˆ°æ–‡æ¡£: {latest_docx}")
    print(f"ğŸ“… ä¿®æ”¹æ—¶é—´: {latest_docx.stat().st_mtime}")
    
    # åˆ†ææ–‡æ¡£
    analyze_word_document(str(latest_docx))
    
    print("\n" + "=" * 50)
    print("âœ… åˆ†æå®Œæˆ")

if __name__ == '__main__':
    main()
